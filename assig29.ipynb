{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2ef6de-6192-4ca4-b282-5455bb68eb68",
   "metadata": {},
   "source": [
    "## 1.\n",
    "Lasso ( Least Absolute Shrinkage and Selection Operator ) Regression \n",
    "\n",
    "In lasso regression, it is the shrinkage towards zero using an absolute value (L1 penalty or regularization technique) rather than a sum of squares(L2 penalty or regularization technique). Since we know that in ridge regression the coefficients can't be zero.\n",
    "\n",
    "Lasso Regression is used in feature selection using a Shrinkage method also referred to as the penalized regression method. Lasso is short for Least Absolute Shrinkage and Selection Operator, which is used both for regularization and model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41648b77-4f20-4b17-8672-bf33f7183f1e",
   "metadata": {},
   "source": [
    "## 2.\n",
    "What LASSO does well is to provide a principled way to reduce the number of features in a model. In contrast, automated feature selection based on standard linear regression by stepwise selection or choosing features with the lowest p-values has many drawbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402efb1-9cfd-4a35-974d-3009f83efe3c",
   "metadata": {},
   "source": [
    "## 3.\n",
    "The coefficients can be used to understand the impact of each feature on the target variable, and also help in feature selection. In this case, we can see that some of the coefficients are zero, indicating that those features may not be important in predicting the target variable.\n",
    "\n",
    "A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8db42b-8ee1-495f-b178-d748d9293359",
   "metadata": {},
   "source": [
    "## 4.\n",
    "A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafccd49-7743-4483-921a-b616b2f635c3",
   "metadata": {},
   "source": [
    "## 5. \n",
    "Lasso is generally not used for non-linear regression.\n",
    "\n",
    "Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff1872-56f3-4e56-ba3c-d78eea05a09b",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Ridge regression shrinks the coefficients towards zero, while Lasso regression encourages some of them to be exactly zero.\n",
    "\n",
    "In lasso regression, it is the shrinkage towards zero using an absolute value (L1 penalty or regularization technique) rather than a sum of squares(L2 penalty or regularization technique). Since we know that in ridge regression the coefficients can't be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00162929-579a-464e-addd-e3a41973b2ae",
   "metadata": {},
   "source": [
    "## 7.\n",
    "Lasso Regression is one of the best method for handling multicollinearity problem in multiple regression analysis.\n",
    "\n",
    "This regression solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64ab97-4adf-499c-8f48-f21e4c3be10e",
   "metadata": {},
   "source": [
    "## 8.\n",
    "When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit: If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model won't learn enough about the training data to make useful predictions.\n",
    "\n",
    "For lasso regression, the alpha value is 1. The output is the best cross-validated lambda, which comes out to be 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab692f-782c-48f4-9499-1a35576f125f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
