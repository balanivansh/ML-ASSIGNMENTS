{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953b2ca6-e0ca-4698-890a-1f9bc3f48f6c",
   "metadata": {},
   "source": [
    "## 1.\n",
    "GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique.\n",
    "\n",
    "Grid-searching can be applied across machine learning to calculate the best parameters to use for any given model. It is important to note that Grid-searching can be extremely computationally expensive and may take your machine quite a long time to run.\n",
    "\n",
    "In machine learning, the grid search approach is used to identify the ideal values for a model's hyperparameters. Building a grid of hyperparameter values, training a model for each set of values, and assessing the model's performance are the steps to make this model function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a3e12-f6a5-4e33-a2b7-e412e19b2088",
   "metadata": {},
   "source": [
    "## 2.\n",
    "While grid search looks at every possible combination of hyperparameters to find the best model, random search only selects and tests a random combination of hyperparameters. This technique randomly samples from a grid of hyperparameters instead of conducting an exhaustive search.\n",
    "\n",
    "Randomized search cv can be better as it can be more efficient than grid search in some cases since it does not train a separate model for every combination of hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cd3f6-e3eb-4e94-b424-a9ef42708a40",
   "metadata": {},
   "source": [
    "## 3.\n",
    "Data leakage can be defined as: \"A scenario when ML model already has information of test data in training data, but this information would not be available at the time of prediction, called data leakage.\n",
    "\n",
    "It causes high performance while training set, but perform poorly in deployment or production.\"\n",
    "\n",
    "Example of data leakage: Data exposed in transit — Data transmitted via emails, API calls, chat rooms, and other communications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6372ff5-31d6-40ce-ac99-02d1d71b1038",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Data leakage can be prevented by encrypting our files. This makes it much harder for hackers to access our data even if they do manage to steal it. We should also consider using a data loss prevention (DLP) system. This software helps to prevent sensitive information from being leaked.\n",
    "\n",
    "For example, an Intrusion Detection System (IDS) can alert about attacker attempts to access to sensitive data. Antivirus software can prevent attackers from compromising sensitive systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547dc1a6-5f7e-4df0-9483-9ed848a2dd16",
   "metadata": {},
   "source": [
    "## 5.\n",
    "A confusion matrix is a matrix that summarizes the performance of a machine learning model on a set of test data. It is often used to measure the performance of classification models, which aim to predict a categorical label for each input instance.\n",
    "\n",
    "It evaluates the performance of the classification models, when they make predictions on test data, and tells how good our classification model is. It not only tells the error made by the classifiers but also the type of errors such as it is either type-I or type-II error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb076c-6747-4f10-8c56-36c7d618b635",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Recall: The ability of a model to find all the relevant cases within a data set. Mathematically, we define recall as the number of true positives divided by the number of true positives plus the number of false negatives.\n",
    "\n",
    "Precision: The ability of a classification model to identify only the relevant data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e208b-cea6-49d0-9f50-1c8f68973527",
   "metadata": {},
   "source": [
    "## 7.\n",
    "True Positives (TP): The model predicted positive and the actual label is positive\n",
    "\n",
    "True Negative (TN): The model predicted negative and the actual label is negative\n",
    "\n",
    "False Positive (FP): The model predicted positive and the actual label was negative {Type 1 error}  e.g. You predicted that animal is a cat but it actually is not (it’s a dog).\n",
    "\n",
    "False Negative (FN): The model predicted  negative and the actual label was positive {Type 2 error}  e.g. You predicted that animal is not a cat but it actually is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e410fb-c6d2-4640-9a0a-55ad459efb1c",
   "metadata": {},
   "source": [
    "## 8.\n",
    "Common metrics of confusion matrix and its calculation :\n",
    "1) Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN\n",
    "2) Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN\n",
    "3) Precision (true positives / predicted positives) = TP / TP + FP\n",
    "4) Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN\n",
    "5) Specificity (true negatives / all actual negatives) =TN / TN + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de1ad3-14b0-47ad-aee2-107fae8159ef",
   "metadata": {},
   "source": [
    "## 9.\n",
    "The confusion matrix can be used to calculate these metrics. The accuracy is simply the number of correct predictions divided by the total number of predictions. The precision is the number of true positive predictions divided by the total number of positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f876d-2621-49f1-aa5a-274c1d7f8876",
   "metadata": {},
   "source": [
    "## 10.\n",
    "Confusion matrix can be used for potential biases when it successfully detects the error. For e.g. in a cancer detecting scenario\n",
    "\n",
    "False Positive ( Type-1 error):\n",
    "Cases, where the model claims that something has happened when actually it hasn’t i.e patient, doesn’t have cancer but the model predicts cancer.\n",
    "\n",
    "False Negative (Type-2 error):\n",
    "Cases,  where the model claims nothing when actually something has happened i.e patient has cancer but the model doesn’t predict cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932a37b-33b8-43eb-865a-68b1281887c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
